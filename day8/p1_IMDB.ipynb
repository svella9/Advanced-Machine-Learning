{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.random.seed(7)\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path = 'imdb.npz', num_words = top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(7)\n",
    "#load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(path = os.path.join(os.getcwd(), 'imdb.npz'), num_words = top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 20, 100, 28, 77, 6, 542, 503, 20, 48, 342, 470, 7, 4, 4, 20, 286, 38, 76, 4085, 23, 4, 383, 139, 13, 384, 240, 6, 383, 2, 5, 146, 252, 15, 225, 6, 176, 53, 15, 271, 23, 19, 383, 2, 1005, 7, 260, 383, 23, 6, 1813, 2857, 488, 2, 2, 122, 6, 52, 292, 1069, 51, 32, 29, 69, 8, 81, 63, 286, 76, 33, 31, 213, 42, 160, 31, 62, 28, 8, 462, 33, 90, 88, 27, 109, 16, 38, 2, 2, 2, 16, 2659, 11, 41, 217, 17, 4, 1947, 383, 2, 59, 2856, 7, 224, 53, 151, 5, 146, 24, 2, 41, 260, 383, 4, 415, 15, 3405, 46, 4, 91, 8, 72, 11, 14, 20, 16, 2, 2, 11, 41, 1078, 217, 17, 4, 1715, 5, 1947, 322, 225, 142, 44, 307, 1004, 5, 46, 15, 2303, 2, 8, 72, 59, 256, 15, 217, 5, 17, 25, 296, 4, 20, 25, 380, 8, 235, 78, 18, 41, 10, 10, 2, 7, 6, 383, 2, 137, 24, 735, 819, 42, 6, 682, 356, 8, 2, 1553, 9, 179, 2, 5, 127, 6, 1257, 292, 11, 800, 25, 89, 2066, 965, 2624, 70, 193, 120, 5, 2457, 4, 55, 183, 11, 113, 25, 104, 545, 7])\n",
      " list([1, 13, 423, 350, 1056, 12, 1428, 61, 602, 727, 114, 542, 109, 943, 5, 65, 347, 12, 9, 184, 729, 8, 312, 2, 11, 15, 4, 513, 84, 977, 815, 5, 1765, 8, 759, 56, 8, 6, 1019, 14, 20, 47, 49, 489, 156, 37, 66, 122, 24, 79, 6, 580, 8, 1497, 32, 7, 68, 1956, 82, 49, 7, 4, 156, 122, 24, 3911, 1109, 18, 68, 555, 2, 2, 16, 6, 52, 267, 132, 11, 27, 1155, 504, 308, 2, 2, 1848, 26, 1339, 11, 68, 555, 2, 2, 122, 4, 118, 15, 29, 100, 19, 338, 819, 12, 9, 254, 8, 838, 90, 17, 6, 2, 3021, 256, 34, 4115, 2, 16, 6, 2, 109, 59, 468, 2, 15, 107, 349, 203, 28, 77, 997, 120, 41, 2, 417, 89, 70, 84, 2106, 209, 2, 262, 372])\n",
      " list([1, 2, 745, 2, 9, 6, 3024, 1410, 1200, 6, 1752, 2, 145, 8, 27, 182, 7, 4624, 89, 70, 6, 167, 28, 6, 177, 19, 745, 2, 3996, 2, 1808, 2, 4289, 2946, 55, 1490, 4871, 2, 2, 2, 2, 2, 2967, 3622, 1514, 2, 5, 6, 97, 141, 6, 437, 7, 58, 14, 20, 9, 6, 212, 15, 9, 24, 163, 260, 6, 2, 11, 4, 177, 61, 2302, 9, 689, 10, 10, 425, 3829, 758, 2, 2, 2, 2, 758, 2, 11, 880, 25, 758, 10, 10])\n",
      " list([1, 86, 125, 387, 72, 380, 19, 6, 3194, 6, 464, 7, 1923, 301, 137, 149, 14, 20, 14, 436, 20, 69, 8, 28, 77, 6, 3328, 25, 124, 40, 2, 13, 2134, 25, 426, 97, 4, 249, 20, 2, 19, 14, 20, 2041, 93, 6, 52, 781, 33, 2, 15, 425, 4, 302, 26, 7, 265, 338, 4, 114, 414, 9, 40, 6, 2, 7, 7, 1801, 2586, 39, 175, 503, 189, 20, 126, 93, 4, 156, 146, 2, 26, 424, 8, 30, 11, 1170, 246, 531, 7, 12, 262, 33, 4, 454, 97, 12, 306, 40, 507, 424, 8, 30, 11, 312, 42, 655, 396, 12, 166, 57, 281, 4, 4579, 170, 187, 880, 84, 218, 4, 222, 227, 737, 1361, 33, 4, 130, 54, 36, 2, 2, 403, 5, 29, 2, 4, 328, 232, 5, 4579, 26, 199, 1104, 242, 46, 7, 2143, 36, 71, 23, 68, 236, 136, 5, 33, 4, 954, 414])]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truncate and pad input sequence\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen = max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen = max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                16600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 176,651\n",
      "Trainable params: 176,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#create the model\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length, input_length = max_review_length))\n",
    "model.add(LSTM(50)) #50 neurons\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KNatarajan\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 202s 8ms/step - loss: 0.4456 - acc: 0.7906\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 201s 8ms/step - loss: 0.2832 - acc: 0.8886\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 201s 8ms/step - loss: 0.2417 - acc: 0.9069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9126407f98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, nb_epoch = 3, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.36%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print('Accuracy: %.2f%%' %(scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
